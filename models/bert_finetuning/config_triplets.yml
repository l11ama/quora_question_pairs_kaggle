# Dataset params
path_to_data: './data/'                                  # Path to a folder with CSV files
train_file_name: 'triplets_train.csv'                           # Train file name located in <path_to_data>
anchor_col_name: 'anchor_q'                                  # Name of a text field in each CSV file
pos_col_name: 'pos_q'                                  # Name of a text field in each CSV file
neg_col_name: 'neg_q'                                # Name of a label (tagret) field in train/validation CSV file

# Bert training params
path_to_pretrained_model: './models/bert_finetuning/uncased_L-12_H-768_A-12'    # Path to a folder with pretrained BERT model
path_to_output_model: './models/bert_finetuning/'                              # Path to output fine-tuned BERT model
output_model_file_name: 'bert_pytorch.bin'             # Output fine-tuned BERT model name
max_seq_length: 150                                    # Maximal sequence length for BERT
batch_size: 32                                         # Batch size
epochs: 2                                              # Number of training epochs
apex_mixed_precision: True                            # Whether to use nvidia apex mixed-precision training
lrate: 2e-5                                            # Learning rate
lrate_clf: 1e-4
warmup: 0.05                                           # Percent of iterations to perform warmup
accum_steps: 3                                         # Number of steps for batch accumulation
lin_dim: 512 # clf hidden layer dim
lin_dropout_prob: 0.15  # clf dropout


# CUDA params
torch_device: 0                                        # GPU device index to use

# Other params
toy: False                                              # Whether to perform a quick test - read first 500 lines from each file
seed: 11                                               # Random seed
