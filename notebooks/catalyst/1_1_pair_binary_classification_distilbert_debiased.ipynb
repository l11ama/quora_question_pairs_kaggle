{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Pair binary classification with DistillBert and Catalyst\n",
    "    \n",
    "<img src='https://habrastorage.org/webt/ne/n_/ow/nen_ow49hxu8zrkgolq1rv3xkhi.png'>\n",
    "    \n",
    "\n",
    "1. **Gradient accumulation.** Doing one optimization step for several bachward steps. Well explained in [this post](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) by HuggingFace\n",
    "1. **Mixed-precision training.** Handled by [Nvidia Apex](https://github.com/NVIDIA/apex) and reused by Catalyst\n",
    "1. **Learning rate schedule.** Standard thing when training deep neural networks, Catalysts handles lot of them\n",
    "1. **Sequence bucketing (soon).** The main idea is that you can group long sentences with long ones, short ones with short ones and thus do less padding. Three approaches are described in [this Kernel](https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Mapping, List\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Numpy and Pandas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformers \n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "# Catalyst\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.callbacks import AccuracyCallback, F1ScoreCallback, OptimizerCallback, SchedulerCallback\n",
    "from catalyst.dl.callbacks import CheckpointCallback, InferCallback, CriterionCallback\n",
    "from catalyst.utils import set_global_seed, prepare_cudnn, set_requires_grad\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sources\n",
    "os.chdir('../../')\n",
    "\n",
    "from pair_classification.catalyst.data.nlp.pair_bin_classify_debiased import TextPairBinaryClfDebiasedDataset\n",
    "from pair_classification.catalyst.contrib.models.nlp.bert.distil_pair_bin_classify import DistilBertForSequencePairBinaryClassification\n",
    "from pair_classification.catalyst.contrib.criterion.bce import SampleWeightedBCELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased' # pretrained model from Transformers\n",
    "LOG_DIR = \"./models/catalyst/logdir\"    # for training logs and tensorboard visualizations\n",
    "NUM_EPOCHS = 20                         # smth around 2-6 epochs is typically fine when finetuning transformers\n",
    "BATCH_SIZE = 64                        # depends on your available GPU memory (in combination with max seq length)\n",
    "MAX_SEQ_LENGTH = 150                   # depends on your available GPU memory (in combination with batch size)\n",
    "LEARN_RATE = 5e-5                      # learning rate is typically ~1e-5 for transformers\n",
    "ACCUM_STEPS = 4                        # one optimization step for that many backward passes\n",
    "SEED = 11                              # random seed for reproducibility\n",
    "POSITIVE_WEIGHT = None               # positive weight constant  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionaly, we install [Nvidia Apex](https://github.com/NVIDIA/apex) to reuse AMP - automatic mixed-precision training.**\n",
    "\n",
    "The idea is that we can use float16 format for faster training, only switching tio float32 when necessary. \n",
    "Here we'll only need to tell Catalyst to use fp16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP16_PARAMS = None\n",
    "FP16_PARAMS = dict(opt_level=\"O1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "Amazon product reviews - [competition](https://www.kaggle.com/c/amazon-pet-product-reviews-classification).\n",
    "Given text of a review, we need to classify it into one of 6 categories: dogs, cats, fish aquatic pets, birds, and two others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce, download the data and customize this path\n",
    "PATH_TO_DATA = './data/debiased/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH_TO_DATA + 'train.csv', index_col='id').fillna('')[:128]\n",
    "valid_df = pd.read_csv(PATH_TO_DATA + 'valid.csv', index_col='id').fillna('')[:64]\n",
    "test_df = pd.read_csv('./data/test.csv', index_col='test_id').fillna('')[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130057</th>\n",
       "      <td>208794</td>\n",
       "      <td>208795</td>\n",
       "      <td>What is the history of Kuala Lumpur, Malaysia?</td>\n",
       "      <td>What is there to do in Kuala Lumpur, Malaysia?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395808</th>\n",
       "      <td>528827</td>\n",
       "      <td>528828</td>\n",
       "      <td>How much control do US president have over mil...</td>\n",
       "      <td>How much control does a sitting President have...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71099</th>\n",
       "      <td>122407</td>\n",
       "      <td>122408</td>\n",
       "      <td>What are some of the awesome places to visit i...</td>\n",
       "      <td>What are some awesome places one can visit in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238614</th>\n",
       "      <td>350029</td>\n",
       "      <td>350030</td>\n",
       "      <td>How do I live happy even though I am ugly?</td>\n",
       "      <td>How do I be happy when I am extremely ugly?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146864</th>\n",
       "      <td>231907</td>\n",
       "      <td>7084</td>\n",
       "      <td>How do I get a girl who doesn't know you like ...</td>\n",
       "      <td>How do you know the girl you like doesn't like...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "id                                                                          \n",
       "130057  208794  208795     What is the history of Kuala Lumpur, Malaysia?   \n",
       "395808  528827  528828  How much control do US president have over mil...   \n",
       "71099   122407  122408  What are some of the awesome places to visit i...   \n",
       "238614  350029  350030         How do I live happy even though I am ugly?   \n",
       "146864  231907    7084  How do I get a girl who doesn't know you like ...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "id                                                                        \n",
       "130057     What is there to do in Kuala Lumpur, Malaysia?             0   \n",
       "395808  How much control does a sitting President have...             0   \n",
       "71099   What are some awesome places one can visit in ...             0   \n",
       "238614        How do I be happy when I am extremely ugly?             1   \n",
       "146864  How do you know the girl you like doesn't like...             0   \n",
       "\n",
       "         weights  \n",
       "id                \n",
       "130057  0.513184  \n",
       "395808  0.786406  \n",
       "71099   0.512839  \n",
       "238614  0.786433  \n",
       "146864  0.561186  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323664</th>\n",
       "      <td>22892</td>\n",
       "      <td>449654</td>\n",
       "      <td>How many chromosomes are in a sperm cell?</td>\n",
       "      <td>How many chromosomes are there in gametes?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361660</th>\n",
       "      <td>491529</td>\n",
       "      <td>491530</td>\n",
       "      <td>Is architecture a good career?</td>\n",
       "      <td>Who is a good architect?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54605</th>\n",
       "      <td>96376</td>\n",
       "      <td>9351</td>\n",
       "      <td>How do I know if I have been blocked on messen...</td>\n",
       "      <td>How can you tell if you've been blocked on Fac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239163</th>\n",
       "      <td>350695</td>\n",
       "      <td>350696</td>\n",
       "      <td>What is my dream all about?</td>\n",
       "      <td>What do you dream about?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192153</th>\n",
       "      <td>36057</td>\n",
       "      <td>18429</td>\n",
       "      <td>Could time travel be a real thing? Could it be...</td>\n",
       "      <td>What is the possibility of time travel becomin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "id                                                                          \n",
       "323664   22892  449654          How many chromosomes are in a sperm cell?   \n",
       "361660  491529  491530                     Is architecture a good career?   \n",
       "54605    96376    9351  How do I know if I have been blocked on messen...   \n",
       "239163  350695  350696                        What is my dream all about?   \n",
       "192153   36057   18429  Could time travel be a real thing? Could it be...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "id                                                                        \n",
       "323664         How many chromosomes are there in gametes?             0   \n",
       "361660                           Who is a good architect?             0   \n",
       "54605   How can you tell if you've been blocked on Fac...             1   \n",
       "239163                           What do you dream about?             0   \n",
       "192153  What is the possibility of time travel becomin...             1   \n",
       "\n",
       "         weights  \n",
       "id                \n",
       "323664  0.513492  \n",
       "361660  0.786517  \n",
       "54605   0.786723  \n",
       "239163  0.535758  \n",
       "192153  0.786602  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Dataset\n",
    "\n",
    "This is left for user to be defined. Catalyst will take care of the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Torch Datasets with train, validation, and test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextPairBinaryClfDebiasedDataset(\n",
    "    texts_left=train_df['question1'].values.tolist(),\n",
    "    texts_right=train_df['question2'].values.tolist(),\n",
    "    labels=train_df['is_duplicate'].values.tolist(),\n",
    "    weights=train_df['weights'].values.tolist(),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "valid_dataset = TextPairBinaryClfDebiasedDataset(\n",
    "    texts_left=valid_df['question1'].values.tolist(),\n",
    "    texts_right=valid_df['question2'].values.tolist(),\n",
    "    labels=valid_df['is_duplicate'].values.tolist(),\n",
    "    weights=valid_df['weights'].values.tolist(),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "test_dataset = TextPairBinaryClfDebiasedDataset(\n",
    "    texts_left=test_df['question1'].values.tolist(),\n",
    "    texts_right=test_df['question2'].values.tolist(),\n",
    "    labels=None,\n",
    "    weights=None,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the training dataset instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid1                                                       528827\n",
       "qid2                                                       528828\n",
       "question1       How much control do US president have over mil...\n",
       "question2       How much control does a sitting President have...\n",
       "is_duplicate                                                    0\n",
       "weights                                                  0.786406\n",
       "Name: 395808, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features_left': tensor([ 101, 2129, 2172, 2491, 2079, 2149, 2343, 2031, 2058, 2510, 3821, 1029,\n",
      "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0]),\n",
      " 'features_right': tensor([ 101, 2129, 2172, 2491, 2515, 1037, 3564, 2343, 2031, 2058, 3171, 3930,\n",
      "        2076, 2010, 2030, 2014, 2744, 1029,  102,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0]),\n",
      " 'mask_left': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], dtype=torch.int8),\n",
      " 'mask_right': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], dtype=torch.int8),\n",
      " 'targets': tensor([0.]),\n",
      " 'weights': tensor([0.7864])}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we define standard PyTorch loaders. This dictionary will be fed to Catalyst.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loaders = {\n",
    "    \"train\": DataLoader(dataset=train_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True),\n",
    "    \"valid\": DataLoader(dataset=valid_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False)    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "It's going to be a slightly simplified version of [`DistilBertForSequenceClassification`](https://github.com/huggingface/transformers/blob/master/transformers/modeling_distilbert.py#L547) by HuggingFace.\n",
    "We need only predicted probabilities as output, nothing more - we don't need neither loss to be output nor hidden states or attentions (as in the original implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequencePairBinaryClassification(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "First we specify criterion, optimizer and scheduler (pure PyTorch). Then Catalyst stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SampleWeightedBCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Deep Learning experiments, Catalyst resorts to the [`Runner`](https://catalyst-team.github.io/catalyst/api/dl.html#catalyst.dl.core.runner.Runner) abstraction, in particular, to [`SupervisedRunner`](https://catalyst-team.github.io/catalyst/api/dl.html#module-catalyst.dl.runner.supervised).\n",
    "\n",
    "`SupervisedRunner` implements the following methods:\n",
    " - `train` - starts the training process of the model\n",
    " - `predict_loader` - makes a prediction on the whole loader with the specified model\n",
    " - `infer` - makes the inference on the model\n",
    " \n",
    "To train the model within this interface you pass the following to the `train` method:\n",
    " - model (`torch.nn.Module`) – PyTorch model to train\n",
    " - criterion (`nn.Module`) – PyTorch criterion function for training\n",
    " - optimizer (`optim.Optimizer`) – PyTorch optimizer for training\n",
    " - loaders (dict) – dictionary containing one or several `torch.utils.data.DataLoader` for training and validation\n",
    " - logdir (str) – path to output directory. There Catalyst will write logs, will dump the best model and the actual code to train the model\n",
    " - callbacks – list of Catalyst callbacks\n",
    " - scheduler (`optim.lr_scheduler._LRScheduler`) – PyTorch scheduler for training\n",
    " - ...\n",
    " \n",
    "In our case we'll pass the created `DistilBertForSequenceClassification` model, cross-entropy criterion, Adam optimizer, scheduler and data loaders that we created earlier. Also, we'll be tracking accuracy and thus will need `AccuracyCallback`. To perform batch accumulation, we'll be using `OptimizationCallback`.\n",
    "\n",
    "There are many more useful [callbacks](https://catalyst-team.github.io/catalyst/api/dl.html#module-catalyst.dl.callbacks.checkpoint) implemented, also check out [Catalyst examples](https://github.com/catalyst-team/catalyst/tree/master/examples/notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"    # can be changed in case of multiple GPUs onboard\n",
    "set_global_seed(SEED)                       # reproducibility\n",
    "prepare_cudnn(deterministic=True)           # reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a small wrapper around Catalyst's runner to be able to pass masks to it\n",
    "class BertSupervisedRunner(SupervisedRunner):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, input_key=(\n",
    "            'features_left',\n",
    "            'mask_left',\n",
    "            'features_right',\n",
    "            'mask_right'\n",
    "        ), **kwargs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "1/1 * Epoch (train): 100% 2/2 [00:04<00:00,  2.29s/it, _timers/_fps=32.465, accuracy01=34.375, f1_score=0.364, loss=0.598]\n",
      "1/1 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.08s/it, _timers/_fps=33.064, accuracy01=37.500, f1_score=0.421, loss=0.596]\n",
      "[2019-12-08 23:12:12,341] \n",
      "1/1 * Epoch 1 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.0235 | _timers/batch_time=2.1458 | _timers/data_time=0.0574 | _timers/model_time=2.0884 | accuracy01=38.2812 | f1_score=0.3706 | loss=0.5761\n",
      "1/1 * Epoch 1 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=33.0641 | _timers/batch_time=1.9356 | _timers/data_time=0.0535 | _timers/model_time=1.8821 | accuracy01=37.5000 | f1_score=0.4212 | loss=0.5955\n",
      "Top best models:\n",
      "models/catalyst/logdir/checkpoints//train.1.pth\t0.5955\n",
      "CPU times: user 5.82 s, sys: 4.46 s, total: 10.3 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# freeze bert\n",
    "set_requires_grad(getattr(model, 'distilbert'), False)\n",
    "\n",
    "# model runner\n",
    "runner = BertSupervisedRunner()\n",
    "\n",
    "callbacks = OrderedDict({\n",
    "    '_criterion': CriterionCallback(input_key=['targets', 'weights']),\n",
    "    '_optimizer': OptimizerCallback(accumulation_steps=ACCUM_STEPS),\n",
    "    '_saver': CheckpointCallback(),\n",
    "    '_scheduler': SchedulerCallback(),\n",
    "    'accuracy': AccuracyCallback(num_classes=1, threshold=0.5, activation='Sigmoid'),\n",
    "    'f1': F1ScoreCallback()\n",
    "})\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_val_loaders,\n",
    "    callbacks=callbacks,\n",
    "    fp16=FP16_PARAMS,\n",
    "    logdir=LOG_DIR,\n",
    "    num_epochs=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  8 23:12:12 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   60C    P0    72W / 149W |    825MiB / 11441MiB |     19%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      3149      C   ...a3/envs/quora_question_pairs/bin/python   814MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BertSupervisedRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "=> loading checkpoint ./models/catalyst/logdir/checkpoints/best_full.pth\n",
      "loaded checkpoint ./models/catalyst/logdir/checkpoints/best_full.pth (epoch 1)\n",
      "1/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.14s/it, _timers/_fps=32.274, accuracy01=32.812, f1_score=0.361, loss=0.551]\n",
      "1/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.09s/it, _timers/_fps=32.827, accuracy01=37.500, f1_score=0.421, loss=0.596]\n",
      "[2019-12-08 23:12:37,945] \n",
      "1/20 * Epoch 2 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=32.4228 | _timers/batch_time=1.9740 | _timers/data_time=0.0598 | _timers/model_time=1.9141 | accuracy01=36.7188 | f1_score=0.3696 | loss=0.5782\n",
      "1/20 * Epoch 2 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=32.8271 | _timers/batch_time=1.9496 | _timers/data_time=0.0561 | _timers/model_time=1.8934 | accuracy01=37.5000 | f1_score=0.4212 | loss=0.5955\n",
      "2/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.34s/it, _timers/_fps=30.729, accuracy01=76.562, f1_score=0.330, loss=0.555]\n",
      "2/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.11s/it, _timers/_fps=32.533, accuracy01=64.062, f1_score=0.411, loss=0.583]\n",
      "[2019-12-08 23:13:21,278] \n",
      "2/20 * Epoch 3 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.1665 | _timers/batch_time=2.1223 | _timers/data_time=0.0591 | _timers/model_time=2.0632 | accuracy01=55.4688 | f1_score=0.3627 | loss=0.5652\n",
      "2/20 * Epoch 3 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=32.5325 | _timers/batch_time=1.9673 | _timers/data_time=0.0563 | _timers/model_time=1.9109 | accuracy01=64.0625 | f1_score=0.4109 | loss=0.5830\n",
      "3/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.43s/it, _timers/_fps=30.319, accuracy01=60.938, f1_score=0.380, loss=0.526]\n",
      "3/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.21s/it, _timers/_fps=31.081, accuracy01=64.062, f1_score=0.399, loss=0.574]\n",
      "[2019-12-08 23:14:02,131] \n",
      "3/20 * Epoch 4 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=29.6679 | _timers/batch_time=2.1583 | _timers/data_time=0.0610 | _timers/model_time=2.0972 | accuracy01=67.1875 | f1_score=0.3605 | loss=0.5563\n",
      "3/20 * Epoch 4 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.0809 | _timers/batch_time=2.0591 | _timers/data_time=0.0572 | _timers/model_time=2.0019 | accuracy01=64.0625 | f1_score=0.3990 | loss=0.5743\n",
      "4/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.29s/it, _timers/_fps=31.871, accuracy01=70.312, f1_score=0.363, loss=0.542]\n",
      "4/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.11s/it, _timers/_fps=32.647, accuracy01=64.062, f1_score=0.399, loss=0.574]\n",
      "[2019-12-08 23:14:30,445] \n",
      "4/20 * Epoch 5 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.4658 | _timers/batch_time=2.0343 | _timers/data_time=0.0619 | _timers/model_time=1.9723 | accuracy01=71.0938 | f1_score=0.3564 | loss=0.5317\n",
      "4/20 * Epoch 5 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=32.6466 | _timers/batch_time=1.9604 | _timers/data_time=0.0565 | _timers/model_time=1.9038 | accuracy01=64.0625 | f1_score=0.3990 | loss=0.5743\n",
      "5/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.32s/it, _timers/_fps=31.803, accuracy01=82.812, f1_score=0.245, loss=0.519]\n",
      "5/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.13s/it, _timers/_fps=32.344, accuracy01=64.062, f1_score=0.382, loss=0.567]\n",
      "[2019-12-08 23:15:30,043] \n",
      "5/20 * Epoch 6 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.5869 | _timers/batch_time=2.0957 | _timers/data_time=0.0609 | _timers/model_time=2.0348 | accuracy01=71.0938 | f1_score=0.3384 | loss=0.5148\n",
      "5/20 * Epoch 6 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=32.3439 | _timers/batch_time=1.9787 | _timers/data_time=0.0574 | _timers/model_time=1.9212 | accuracy01=64.0625 | f1_score=0.3817 | loss=0.5666\n",
      "6/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.42s/it, _timers/_fps=30.402, accuracy01=65.625, f1_score=0.381, loss=0.483]\n",
      "6/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.11s/it, _timers/_fps=32.600, accuracy01=64.062, f1_score=0.360, loss=0.563]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment, check)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/callbacks/checkpoint.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mmain_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mminimize_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         )\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/callbacks/checkpoint.py\u001b[0m in \u001b[0;36mprocess_checkpoint\u001b[0;34m(self, logdir, checkpoint, is_best, main_metric, minimize_metric)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mis_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         )\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/utils/checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(checkpoint, logdir, suffix, is_best, is_last, special_suffix)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{logdir}/{suffix}.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/runner/supervised.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, loaders, logdir, callbacks, scheduler, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, monitoring_params, check)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mmonitoring_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitoring_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     def infer(\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment, check)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}_post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}_post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/core/state.py\u001b[0m in \u001b[0;36mon_exception_post\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_exception_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/kaggle/catalyst/catalyst/dl/callbacks/logging.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Early exiting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_reraise_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# unfreeze bert\n",
    "set_requires_grad(getattr(model, 'distilbert'), True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "callbacks = OrderedDict({\n",
    "    '_criterion': CriterionCallback(input_key=['targets', 'weights']),\n",
    "    '_optimizer': OptimizerCallback(accumulation_steps=ACCUM_STEPS),\n",
    "    '_scheduler': SchedulerCallback(),\n",
    "    '_saver': CheckpointCallback(resume=f\"{LOG_DIR}/checkpoints/best_full.pth\", save_n_best=5),\n",
    "    'accuracy': AccuracyCallback(num_classes=1, threshold=0.5, activation='Sigmoid'),\n",
    "    'f1': F1ScoreCallback()\n",
    "})\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_val_loaders,\n",
    "    callbacks=callbacks,\n",
    "    fp16=FP16_PARAMS,\n",
    "    logdir=LOG_DIR,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  8 23:16:25 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   65C    P0    74W / 149W |   1899MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      3149      C   ...a3/envs/quora_question_pairs/bin/python  1886MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot metrics\n",
    "\n",
    "<img src=\"https://habrastorage.org/webt/ki/ib/hy/kiibhyp373r65zriwruroiqitky.jpeg\" width=30% />\n",
    "\n",
    "There are at least 4 ways to monitor training:\n",
    "\n",
    "### 1. Good old tqdm\n",
    "There above it's set with a flag `verbose` in `runner.train`. Actually, it's not that bad :)\n",
    "\n",
    "<img src='https://habrastorage.org/webt/ta/1s/98/ta1s988ghabz412weaq0lgs_cke.png'> \n",
    "\n",
    "\n",
    "### 2. Weights & Biases\n",
    "\n",
    "Before launching training, you can run [Weighs & Biases](https://app.wandb.ai/) inititialization for this project. Execute `wandb init` in a separate terminal window (from the same directory where this notebook is running). `wandb` will ask your API key from https://app.wandb.ai/authorize and project name. The rest will be picked up by Catalyst's `SupervisedWandbRunner` (so you'll need to import this instead of `SupervisedRunner`). \n",
    "Following the links printed above (smth. like  https://app.wandb.ai/yorko/catalyst-nlp-bert) we can keep track of loss and metrics.\n",
    "\n",
    "### 3. Tensorboard\n",
    "During training, logs are written to `LOG_DIR` specified above. \n",
    "Similtaneously with training, you can run `tensorboard --logdir $LOG_DIR` (in another terminal tab, in case of training on a server, I also had to add a `--bin_all` flag),\n",
    "and you'll get a nice dashboard. Here we see how accuracy and loss change during training.\n",
    "\n",
    "<img src=\"https://habrastorage.org/webt/2a/sx/mo/2asxmoizgcpf2fnhjjkfhvf70aw.png\" width=50% />\n",
    "\n",
    "### 4. Offline metric plotting\n",
    "\n",
    "If your training is pretty fast and/or you're not interested in tracking training progress, you can just plot losses and metrics once the training is done. Looks like it won't work in Kernels though but try it locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Torch loader for the test set and launch `infer` to actually make predictions fot the test set. First, we load the best model checkpoint, then make inference with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = {\n",
    "    \"test\": DataLoader(dataset=test_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint ./models/catalyst/logdir/checkpoints/best.pth\n",
      "loaded checkpoint ./models/catalyst/logdir/checkpoints/best.pth (epoch 6)\n",
      "1/1 * Epoch (test): 100% 2/2 [00:04<00:00,  2.24s/it, _timers/_fps=32.010]\n",
      "Top best models:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.infer(\n",
    "    model=model,\n",
    "    loaders=test_loaders,\n",
    "    callbacks=[\n",
    "        CheckpointCallback(\n",
    "            resume=f\"{LOG_DIR}/checkpoints/best.pth\"\n",
    "        ),\n",
    "        InferCallback(),\n",
    "    ],   \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = runner.callbacks[0].predictions['logits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have predicted probabilities, let's finally create a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df = pd.read_csv(PATH_TO_DATA + 'sample_submission.csv',\n",
    "                           index_col='test_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-68d7a0e806c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpair_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_finetuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigmoid_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_sub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_duplicate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "from pair_classification.bert_finetuning.util import sigmoid_np\n",
    "\n",
    "sample_sub_df['is_duplicate'] = sigmoid_np(predicted_probs.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.to_csv('distillbert_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quora_question_pairs",
   "language": "python",
   "name": "quora_question_pairs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
