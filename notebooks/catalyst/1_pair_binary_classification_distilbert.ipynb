{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Pair binary classification with DistillBert and Catalyst\n",
    "    \n",
    "<img src='https://habrastorage.org/webt/ne/n_/ow/nen_ow49hxu8zrkgolq1rv3xkhi.png'>\n",
    "    \n",
    "\n",
    "1. **Gradient accumulation.** Doing one optimization step for several bachward steps. Well explained in [this post](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) by HuggingFace\n",
    "1. **Mixed-precision training.** Handled by [Nvidia Apex](https://github.com/NVIDIA/apex) and reused by Catalyst\n",
    "1. **Learning rate schedule.** Standard thing when training deep neural networks, Catalysts handles lot of them\n",
    "1. **Sequence bucketing (soon).** The main idea is that you can group long sentences with long ones, short ones with short ones and thus do less padding. Three approaches are described in [this Kernel](https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Mapping, List\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Numpy and Pandas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformers \n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "# Catalyst\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.callbacks import AccuracyCallback, F1ScoreCallback, OptimizerCallback, SchedulerCallback\n",
    "from catalyst.dl.callbacks import CheckpointCallback, InferCallback, CriterionCallback\n",
    "from catalyst.utils import set_global_seed, prepare_cudnn, set_requires_grad\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sources\n",
    "os.chdir('../../')\n",
    "\n",
    "from pair_classification.catalyst.data.nlp.pair_bin_classify import TextPairBinaryClfDataset\n",
    "from pair_classification.catalyst.contrib.models.nlp.bert.distil_pair_bin_classify import DistilBertForSequencePairBinaryClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased' # pretrained model from Transformers\n",
    "LOG_DIR = \"./models/catalyst/logdir\"    # for training logs and tensorboard visualizations\n",
    "NUM_EPOCHS = 20                         # smth around 2-6 epochs is typically fine when finetuning transformers\n",
    "BATCH_SIZE = 64                        # depends on your available GPU memory (in combination with max seq length)\n",
    "MAX_SEQ_LENGTH = 150                   # depends on your available GPU memory (in combination with batch size)\n",
    "LEARN_RATE = 5e-5                      # learning rate is typically ~1e-5 for transformers\n",
    "ACCUM_STEPS = 4                        # one optimization step for that many backward passes\n",
    "SEED = 11                              # random seed for reproducibility\n",
    "POSITIVE_WEIGHT = None               # positive weight constant  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionaly, we install [Nvidia Apex](https://github.com/NVIDIA/apex) to reuse AMP - automatic mixed-precision training.**\n",
    "\n",
    "The idea is that we can use float16 format for faster training, only switching tio float32 when necessary. \n",
    "Here we'll only need to tell Catalyst to use fp16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP16_PARAMS = None\n",
    "FP16_PARAMS = dict(opt_level=\"O1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "Amazon product reviews - [competition](https://www.kaggle.com/c/amazon-pet-product-reviews-classification).\n",
    "Given text of a review, we need to classify it into one of 6 categories: dogs, cats, fish aquatic pets, birds, and two others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce, download the data and customize this path\n",
    "PATH_TO_DATA = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH_TO_DATA + 'train.csv', index_col='id').fillna('')\n",
    "X_train = np.arange(len(train_df))\n",
    "y_train = train_df['is_duplicate'].to_numpy(dtype=np.int32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, stratify=y_train, random_state=SEED)\n",
    "valid_df = train_df.iloc[X_val]\n",
    "train_df = train_df.iloc[X_train]\n",
    "valid_df.to_csv(PATH_TO_DATA + 'valid.csv', index_label='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH_TO_DATA + 'train.csv', index_col='id').fillna('')[:128]\n",
    "valid_df = pd.read_csv(PATH_TO_DATA + 'valid.csv', index_col='id').fillna('')[:64]\n",
    "test_df = pd.read_csv(PATH_TO_DATA + 'test.csv', index_col='test_id').fillna('')[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "id                                                                  \n",
       "0      1     2  What is the step by step guide to invest in sh...   \n",
       "1      3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      5     6  How can I increase the speed of my internet co...   \n",
       "3      7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4      9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "id                                                                   \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323664</th>\n",
       "      <td>22892</td>\n",
       "      <td>449654</td>\n",
       "      <td>How many chromosomes are in a sperm cell?</td>\n",
       "      <td>How many chromosomes are there in gametes?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361660</th>\n",
       "      <td>491529</td>\n",
       "      <td>491530</td>\n",
       "      <td>Is architecture a good career?</td>\n",
       "      <td>Who is a good architect?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54605</th>\n",
       "      <td>96376</td>\n",
       "      <td>9351</td>\n",
       "      <td>How do I know if I have been blocked on messen...</td>\n",
       "      <td>How can you tell if you've been blocked on Fac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239163</th>\n",
       "      <td>350695</td>\n",
       "      <td>350696</td>\n",
       "      <td>What is my dream all about?</td>\n",
       "      <td>What do you dream about?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192153</th>\n",
       "      <td>36057</td>\n",
       "      <td>18429</td>\n",
       "      <td>Could time travel be a real thing? Could it be...</td>\n",
       "      <td>What is the possibility of time travel becomin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "id                                                                          \n",
       "323664   22892  449654          How many chromosomes are in a sperm cell?   \n",
       "361660  491529  491530                     Is architecture a good career?   \n",
       "54605    96376    9351  How do I know if I have been blocked on messen...   \n",
       "239163  350695  350696                        What is my dream all about?   \n",
       "192153   36057   18429  Could time travel be a real thing? Could it be...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "id                                                                       \n",
       "323664         How many chromosomes are there in gametes?             0  \n",
       "361660                           Who is a good architect?             0  \n",
       "54605   How can you tell if you've been blocked on Fac...             1  \n",
       "239163                           What do you dream about?             0  \n",
       "192153  What is the possibility of time travel becomin...             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Dataset\n",
    "\n",
    "This is left for user to be defined. Catalyst will take care of the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Torch Datasets with train, validation, and test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextPairBinaryClfDataset(\n",
    "    texts_left=train_df['question1'].values.tolist(),\n",
    "    texts_right=train_df['question2'].values.tolist(),\n",
    "    labels=train_df['is_duplicate'].values.tolist(),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "valid_dataset = TextPairBinaryClfDataset(\n",
    "    texts_left=valid_df['question1'].values.tolist(),\n",
    "    texts_right=valid_df['question2'].values.tolist(),\n",
    "    labels=valid_df['is_duplicate'].values.tolist(),\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "test_dataset = TextPairBinaryClfDataset(\n",
    "    texts_left=test_df['question1'].values.tolist(),\n",
    "    texts_right=test_df['question2'].values.tolist(),\n",
    "    labels=None,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the training dataset instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid1                                                            3\n",
       "qid2                                                            4\n",
       "question1       What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "question2       What would happen if the Indian government sto...\n",
       "is_duplicate                                                    0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features_left': tensor([  101,  2054,  2003,  1996,  2466,  1997, 12849, 10606, 16506,  1006,\n",
      "        12849,  2232,  1011,  1045,  1011,  2053,  2953,  1007,  6323,  1029,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
      " 'features_right': tensor([  101,  2054,  2052,  4148,  2065,  1996,  2796,  2231, 10312,  1996,\n",
      "        12849, 10606, 16506,  1006, 12849,  2232,  1011,  1045,  1011,  2053,\n",
      "         2953,  1007,  6323,  2067,  1029,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
      " 'mask_left': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], dtype=torch.int8),\n",
      " 'mask_right': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], dtype=torch.int8),\n",
      " 'targets': tensor([0.])}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we define standard PyTorch loaders. This dictionary will be fed to Catalyst.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loaders = {\n",
    "    \"train\": DataLoader(dataset=train_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True),\n",
    "    \"valid\": DataLoader(dataset=valid_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False)    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "It's going to be a slightly simplified version of [`DistilBertForSequenceClassification`](https://github.com/huggingface/transformers/blob/master/transformers/modeling_distilbert.py#L547) by HuggingFace.\n",
    "We need only predicted probabilities as output, nothing more - we don't need neither loss to be output nor hidden states or attentions (as in the original implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequencePairBinaryClassification(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "First we specify criterion, optimizer and scheduler (pure PyTorch). Then Catalyst stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = None\n",
    "if POSITIVE_WEIGHT:\n",
    "    weight = torch.FloatTensor(POSITIVE_WEIGHT).cuda()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Deep Learning experiments, Catalyst resorts to the [`Runner`](https://catalyst-team.github.io/catalyst/api/dl.html#catalyst.dl.core.runner.Runner) abstraction, in particular, to [`SupervisedRunner`](https://catalyst-team.github.io/catalyst/api/dl.html#module-catalyst.dl.runner.supervised).\n",
    "\n",
    "`SupervisedRunner` implements the following methods:\n",
    " - `train` - starts the training process of the model\n",
    " - `predict_loader` - makes a prediction on the whole loader with the specified model\n",
    " - `infer` - makes the inference on the model\n",
    " \n",
    "To train the model within this interface you pass the following to the `train` method:\n",
    " - model (`torch.nn.Module`) – PyTorch model to train\n",
    " - criterion (`nn.Module`) – PyTorch criterion function for training\n",
    " - optimizer (`optim.Optimizer`) – PyTorch optimizer for training\n",
    " - loaders (dict) – dictionary containing one or several `torch.utils.data.DataLoader` for training and validation\n",
    " - logdir (str) – path to output directory. There Catalyst will write logs, will dump the best model and the actual code to train the model\n",
    " - callbacks – list of Catalyst callbacks\n",
    " - scheduler (`optim.lr_scheduler._LRScheduler`) – PyTorch scheduler for training\n",
    " - ...\n",
    " \n",
    "In our case we'll pass the created `DistilBertForSequenceClassification` model, cross-entropy criterion, Adam optimizer, scheduler and data loaders that we created earlier. Also, we'll be tracking accuracy and thus will need `AccuracyCallback`. To perform batch accumulation, we'll be using `OptimizationCallback`.\n",
    "\n",
    "There are many more useful [callbacks](https://catalyst-team.github.io/catalyst/api/dl.html#module-catalyst.dl.callbacks.checkpoint) implemented, also check out [Catalyst examples](https://github.com/catalyst-team/catalyst/tree/master/examples/notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"    # can be changed in case of multiple GPUs onboard\n",
    "set_global_seed(SEED)                       # reproducibility\n",
    "prepare_cudnn(deterministic=True)           # reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a small wrapper around Catalyst's runner to be able to pass masks to it\n",
    "class BertSupervisedRunner(SupervisedRunner):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, input_key=(\n",
    "            'features_left',\n",
    "            'mask_left',\n",
    "            'features_right',\n",
    "            'mask_right'\n",
    "        ), **kwargs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "1/1 * Epoch (train): 100% 2/2 [00:04<00:00,  2.32s/it, _timers/_fps=31.428, accuracy01=45.312, f1_score=0.384, loss=0.696]\n",
      "1/1 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.17s/it, _timers/_fps=31.783, accuracy01=46.875, f1_score=0.418, loss=0.692]\n",
      "[2019-12-08 01:00:06,255] \n",
      "1/1 * Epoch 1 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=29.5901 | _timers/batch_time=2.1713 | _timers/data_time=0.0535 | _timers/model_time=2.1177 | accuracy01=52.3438 | f1_score=0.4017 | loss=0.6944\n",
      "1/1 * Epoch 1 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.7834 | _timers/batch_time=2.0136 | _timers/data_time=0.0519 | _timers/model_time=1.9617 | accuracy01=46.8750 | f1_score=0.4177 | loss=0.6919\n",
      "Top best models:\n",
      "models/catalyst/logdir/checkpoints//train.1.pth\t0.6919\n",
      "CPU times: user 5.76 s, sys: 4.14 s, total: 9.89 s\n",
      "Wall time: 9.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# freeze bert\n",
    "set_requires_grad(getattr(model, 'distilbert'), False)\n",
    "\n",
    "# model runner\n",
    "runner = BertSupervisedRunner()\n",
    "\n",
    "callbacks = OrderedDict({\n",
    "    '_criterion': CriterionCallback(),\n",
    "    '_optimizer': OptimizerCallback(accumulation_steps=ACCUM_STEPS),\n",
    "    '_saver': CheckpointCallback(),\n",
    "    '_scheduler': SchedulerCallback(),\n",
    "    'accuracy': AccuracyCallback(num_classes=1, threshold=0.5, activation='Sigmoid'),\n",
    "    'f1': F1ScoreCallback()\n",
    "})\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_val_loaders,\n",
    "    callbacks=callbacks,\n",
    "    fp16=FP16_PARAMS,\n",
    "    logdir=LOG_DIR,\n",
    "    num_epochs=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  8 01:00:06 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   57C    P0    84W / 149W |    825MiB / 11441MiB |     13%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      2881      C   ...a3/envs/quora_question_pairs/bin/python   814MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BertSupervisedRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "=> loading checkpoint ./models/catalyst/logdir/checkpoints/best_full.pth\n",
      "loaded checkpoint ./models/catalyst/logdir/checkpoints/best_full.pth (epoch 1)\n",
      "1/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.28s/it, _timers/_fps=31.631, accuracy01=53.125, f1_score=0.394, loss=0.693]\n",
      "1/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.15s/it, _timers/_fps=31.891, accuracy01=46.875, f1_score=0.418, loss=0.692]\n",
      "[2019-12-08 01:00:32,282] \n",
      "1/20 * Epoch 2 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.7219 | _timers/batch_time=2.0176 | _timers/data_time=0.0564 | _timers/model_time=1.9611 | accuracy01=48.4375 | f1_score=0.4007 | loss=0.6937\n",
      "1/20 * Epoch 2 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.8909 | _timers/batch_time=2.0068 | _timers/data_time=0.0538 | _timers/model_time=1.9530 | accuracy01=46.8750 | f1_score=0.4177 | loss=0.6919\n",
      "2/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.38s/it, _timers/_fps=31.727, accuracy01=68.750, f1_score=0.383, loss=0.670]\n",
      "2/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.18s/it, _timers/_fps=31.462, accuracy01=64.062, f1_score=0.401, loss=0.672]\n",
      "[2019-12-08 01:01:15,786] \n",
      "2/20 * Epoch 3 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.8772 | _timers/batch_time=2.0743 | _timers/data_time=0.0572 | _timers/model_time=2.0170 | accuracy01=64.8438 | f1_score=0.3965 | loss=0.6799\n",
      "2/20 * Epoch 3 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.4618 | _timers/batch_time=2.0342 | _timers/data_time=0.0538 | _timers/model_time=1.9804 | accuracy01=64.0625 | f1_score=0.4009 | loss=0.6722\n",
      "3/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.35s/it, _timers/_fps=31.035, accuracy01=64.062, f1_score=0.410, loss=0.664]\n",
      "3/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.18s/it, _timers/_fps=31.556, accuracy01=64.062, f1_score=0.381, loss=0.660]\n",
      "[2019-12-08 01:01:56,527] \n",
      "3/20 * Epoch 4 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.2987 | _timers/batch_time=2.0450 | _timers/data_time=0.0579 | _timers/model_time=1.9870 | accuracy01=66.4062 | f1_score=0.3931 | loss=0.6601\n",
      "3/20 * Epoch 4 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.5561 | _timers/batch_time=2.0281 | _timers/data_time=0.0540 | _timers/model_time=1.9741 | accuracy01=64.0625 | f1_score=0.3812 | loss=0.6605\n",
      "4/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.39s/it, _timers/_fps=31.373, accuracy01=64.062, f1_score=0.392, loss=0.652]\n",
      "4/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.14s/it, _timers/_fps=32.115, accuracy01=64.062, f1_score=0.381, loss=0.660]\n",
      "[2019-12-08 01:02:23,145] \n",
      "4/20 * Epoch 5 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.3509 | _timers/batch_time=2.1111 | _timers/data_time=0.0564 | _timers/model_time=2.0546 | accuracy01=66.4062 | f1_score=0.3755 | loss=0.6466\n",
      "4/20 * Epoch 5 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=32.1151 | _timers/batch_time=1.9928 | _timers/data_time=0.0545 | _timers/model_time=1.9383 | accuracy01=64.0625 | f1_score=0.3812 | loss=0.6605\n",
      "5/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.41s/it, _timers/_fps=31.431, accuracy01=71.875, f1_score=0.324, loss=0.603]\n",
      "5/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.15s/it, _timers/_fps=31.971, accuracy01=64.062, f1_score=0.360, loss=0.657]\n",
      "[2019-12-08 01:03:01,169] \n",
      "5/20 * Epoch 6 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.3010 | _timers/batch_time=2.1151 | _timers/data_time=0.0558 | _timers/model_time=2.0592 | accuracy01=66.4062 | f1_score=0.3676 | loss=0.6294\n",
      "5/20 * Epoch 6 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.9708 | _timers/batch_time=2.0018 | _timers/data_time=0.0533 | _timers/model_time=1.9485 | accuracy01=64.0625 | f1_score=0.3595 | loss=0.6573\n",
      "6/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.34s/it, _timers/_fps=31.575, accuracy01=71.875, f1_score=0.324, loss=0.606]\n",
      "6/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.23s/it, _timers/_fps=30.735, accuracy01=64.062, f1_score=0.334, loss=0.663]\n",
      "[2019-12-08 01:03:31,621] \n",
      "6/20 * Epoch 7 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.5678 | _timers/batch_time=2.0274 | _timers/data_time=0.0560 | _timers/model_time=1.9713 | accuracy01=66.4062 | f1_score=0.3578 | loss=0.6300\n",
      "6/20 * Epoch 7 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.7353 | _timers/batch_time=2.0823 | _timers/data_time=0.0613 | _timers/model_time=2.0210 | accuracy01=64.0625 | f1_score=0.3339 | loss=0.6627\n",
      "7/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.34s/it, _timers/_fps=31.145, accuracy01=64.062, f1_score=0.353, loss=0.641]\n",
      "7/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.17s/it, _timers/_fps=31.487, accuracy01=64.062, f1_score=0.334, loss=0.663]\n",
      "[2019-12-08 01:03:58,164] \n",
      "7/20 * Epoch 8 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.3436 | _timers/batch_time=2.0420 | _timers/data_time=0.0584 | _timers/model_time=1.9835 | accuracy01=66.4062 | f1_score=0.3414 | loss=0.6236\n",
      "7/20 * Epoch 8 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.4871 | _timers/batch_time=2.0326 | _timers/data_time=0.0534 | _timers/model_time=1.9792 | accuracy01=64.0625 | f1_score=0.3339 | loss=0.6627\n",
      "8/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.34s/it, _timers/_fps=31.567, accuracy01=65.625, f1_score=0.341, loss=0.610]\n",
      "8/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.15s/it, _timers/_fps=31.831, accuracy01=64.062, f1_score=0.309, loss=0.676]\n",
      "[2019-12-08 01:04:24,720] \n",
      "8/20 * Epoch 9 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.4976 | _timers/batch_time=2.0319 | _timers/data_time=0.0555 | _timers/model_time=1.9763 | accuracy01=66.4062 | f1_score=0.3395 | loss=0.6138\n",
      "8/20 * Epoch 9 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.8314 | _timers/batch_time=2.0106 | _timers/data_time=0.0537 | _timers/model_time=1.9568 | accuracy01=64.0625 | f1_score=0.3091 | loss=0.6765\n",
      "9/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.41s/it, _timers/_fps=31.316, accuracy01=65.625, f1_score=0.337, loss=0.618]\n",
      "9/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.14s/it, _timers/_fps=31.916, accuracy01=64.062, f1_score=0.301, loss=0.683]\n",
      "[2019-12-08 01:04:51,388] \n",
      "9/20 * Epoch 10 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.4480 | _timers/batch_time=2.1037 | _timers/data_time=0.0564 | _timers/model_time=2.0472 | accuracy01=66.4062 | f1_score=0.3276 | loss=0.6188\n",
      "9/20 * Epoch 10 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.9160 | _timers/batch_time=2.0053 | _timers/data_time=0.0530 | _timers/model_time=1.9523 | accuracy01=64.0625 | f1_score=0.3014 | loss=0.6831\n",
      "10/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.34s/it, _timers/_fps=31.341, accuracy01=62.500, f1_score=0.351, loss=0.636]\n",
      "10/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.16s/it, _timers/_fps=31.770, accuracy01=64.062, f1_score=0.301, loss=0.683]\n",
      "[2019-12-08 01:05:17,928] \n",
      "10/20 * Epoch 11 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.2761 | _timers/batch_time=2.0463 | _timers/data_time=0.0566 | _timers/model_time=1.9896 | accuracy01=66.4062 | f1_score=0.3398 | loss=0.5949\n",
      "10/20 * Epoch 11 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.7697 | _timers/batch_time=2.0145 | _timers/data_time=0.0545 | _timers/model_time=1.9600 | accuracy01=64.0625 | f1_score=0.3014 | loss=0.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.42s/it, _timers/_fps=31.349, accuracy01=67.188, f1_score=0.355, loss=0.567]\n",
      "11/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.16s/it, _timers/_fps=31.777, accuracy01=64.062, f1_score=0.306, loss=0.681]\n",
      "[2019-12-08 01:05:44,618] \n",
      "11/20 * Epoch 12 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.3903 | _timers/batch_time=2.1080 | _timers/data_time=0.0562 | _timers/model_time=2.0518 | accuracy01=66.4062 | f1_score=0.3477 | loss=0.5885\n",
      "11/20 * Epoch 12 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.7774 | _timers/batch_time=2.0140 | _timers/data_time=0.0539 | _timers/model_time=1.9601 | accuracy01=64.0625 | f1_score=0.3062 | loss=0.6810\n",
      "12/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.36s/it, _timers/_fps=31.304, accuracy01=60.938, f1_score=0.391, loss=0.607]\n",
      "12/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.16s/it, _timers/_fps=31.643, accuracy01=64.062, f1_score=0.312, loss=0.679]\n",
      "[2019-12-08 01:06:11,228] \n",
      "12/20 * Epoch 13 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.4489 | _timers/batch_time=2.0351 | _timers/data_time=0.0547 | _timers/model_time=1.9804 | accuracy01=66.4062 | f1_score=0.3572 | loss=0.5739\n",
      "12/20 * Epoch 13 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.6429 | _timers/batch_time=2.0226 | _timers/data_time=0.0547 | _timers/model_time=1.9678 | accuracy01=64.0625 | f1_score=0.3122 | loss=0.6791\n",
      "13/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.40s/it, _timers/_fps=31.441, accuracy01=65.625, f1_score=0.393, loss=0.548]\n",
      "13/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.15s/it, _timers/_fps=31.838, accuracy01=64.062, f1_score=0.312, loss=0.679]\n",
      "[2019-12-08 01:06:37,886] \n",
      "13/20 * Epoch 14 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.3597 | _timers/batch_time=2.1107 | _timers/data_time=0.0558 | _timers/model_time=2.0549 | accuracy01=66.4062 | f1_score=0.3781 | loss=0.5560\n",
      "13/20 * Epoch 14 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.8384 | _timers/batch_time=2.0101 | _timers/data_time=0.0529 | _timers/model_time=1.9573 | accuracy01=64.0625 | f1_score=0.3122 | loss=0.6791\n",
      "14/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.36s/it, _timers/_fps=31.273, accuracy01=68.750, f1_score=0.384, loss=0.522]\n",
      "14/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.19s/it, _timers/_fps=31.428, accuracy01=64.062, f1_score=0.312, loss=0.682]\n",
      "[2019-12-08 01:07:04,690] \n",
      "14/20 * Epoch 15 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.3350 | _timers/batch_time=2.0425 | _timers/data_time=0.0555 | _timers/model_time=1.9869 | accuracy01=66.4062 | f1_score=0.3911 | loss=0.5415\n",
      "14/20 * Epoch 15 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.4285 | _timers/batch_time=2.0364 | _timers/data_time=0.0537 | _timers/model_time=1.9826 | accuracy01=64.0625 | f1_score=0.3120 | loss=0.6825\n",
      "15/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.41s/it, _timers/_fps=31.324, accuracy01=75.000, f1_score=0.357, loss=0.467]\n",
      "15/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.15s/it, _timers/_fps=31.914, accuracy01=64.062, f1_score=0.301, loss=0.695]\n",
      "[2019-12-08 01:07:31,380] \n",
      "15/20 * Epoch 16 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=30.5974 | _timers/batch_time=2.0929 | _timers/data_time=0.0553 | _timers/model_time=2.0375 | accuracy01=66.4062 | f1_score=0.3976 | loss=0.5256\n",
      "15/20 * Epoch 16 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.9136 | _timers/batch_time=2.0054 | _timers/data_time=0.0534 | _timers/model_time=1.9519 | accuracy01=64.0625 | f1_score=0.3006 | loss=0.6953\n",
      "16/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.36s/it, _timers/_fps=31.175, accuracy01=64.062, f1_score=0.437, loss=0.509]\n",
      "16/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.18s/it, _timers/_fps=31.545, accuracy01=64.062, f1_score=0.301, loss=0.695]\n",
      "[2019-12-08 01:07:57,974] \n",
      "16/20 * Epoch 17 (train): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.1692 | _timers/batch_time=2.0533 | _timers/data_time=0.0566 | _timers/model_time=1.9967 | accuracy01=66.4062 | f1_score=0.4219 | loss=0.4937\n",
      "16/20 * Epoch 17 (valid): _base/lr=5.000e-05 | _base/momentum=0.9000 | _timers/_fps=31.5447 | _timers/batch_time=2.0289 | _timers/data_time=0.0543 | _timers/model_time=1.9745 | accuracy01=64.0625 | f1_score=0.3006 | loss=0.6953\n",
      "17/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.43s/it, _timers/_fps=31.473, accuracy01=65.625, f1_score=0.425, loss=0.499]\n",
      "17/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.17s/it, _timers/_fps=31.690, accuracy01=64.062, f1_score=0.299, loss=0.697]\n",
      "[2019-12-08 01:08:24,703] \n",
      "17/20 * Epoch 18 (train): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=30.5949 | _timers/batch_time=2.0936 | _timers/data_time=0.0552 | _timers/model_time=2.0384 | accuracy01=66.4062 | f1_score=0.4222 | loss=0.4963\n",
      "17/20 * Epoch 18 (valid): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=31.6900 | _timers/batch_time=2.0196 | _timers/data_time=0.0539 | _timers/model_time=1.9657 | accuracy01=64.0625 | f1_score=0.2988 | loss=0.6972\n",
      "18/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.39s/it, _timers/_fps=31.016, accuracy01=65.625, f1_score=0.431, loss=0.495]\n",
      "18/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.17s/it, _timers/_fps=31.577, accuracy01=64.062, f1_score=0.297, loss=0.699]\n",
      "[2019-12-08 01:08:51,341] \n",
      "18/20 * Epoch 19 (train): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=31.0827 | _timers/batch_time=2.0590 | _timers/data_time=0.0564 | _timers/model_time=2.0026 | accuracy01=66.4062 | f1_score=0.4280 | loss=0.4891\n",
      "18/20 * Epoch 19 (valid): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=31.5773 | _timers/batch_time=2.0268 | _timers/data_time=0.0537 | _timers/model_time=1.9731 | accuracy01=64.0625 | f1_score=0.2969 | loss=0.6991\n",
      "19/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.37s/it, _timers/_fps=31.441, accuracy01=70.312, f1_score=0.416, loss=0.450]\n",
      "19/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.16s/it, _timers/_fps=31.769, accuracy01=64.062, f1_score=0.297, loss=0.699]\n",
      "[2019-12-08 01:09:17,941] \n",
      "19/20 * Epoch 20 (train): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=30.7009 | _timers/batch_time=2.0858 | _timers/data_time=0.0564 | _timers/model_time=2.0294 | accuracy01=66.4062 | f1_score=0.4291 | loss=0.4834\n",
      "19/20 * Epoch 20 (valid): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=31.7688 | _timers/batch_time=2.0146 | _timers/data_time=0.0538 | _timers/model_time=1.9607 | accuracy01=64.0625 | f1_score=0.2969 | loss=0.6991\n",
      "20/20 * Epoch (train): 100% 2/2 [00:12<00:00,  6.33s/it, _timers/_fps=31.410, accuracy01=64.062, f1_score=0.435, loss=0.505]\n",
      "20/20 * Epoch (valid): 100% 1/1 [00:02<00:00,  2.16s/it, _timers/_fps=31.742, accuracy01=64.062, f1_score=0.295, loss=0.701]\n",
      "[2019-12-08 01:09:44,465] \n",
      "20/20 * Epoch 21 (train): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=31.5704 | _timers/batch_time=2.0273 | _timers/data_time=0.0565 | _timers/model_time=1.9708 | accuracy01=66.4062 | f1_score=0.4305 | loss=0.4830\n",
      "20/20 * Epoch 21 (valid): _base/lr=5.000e-06 | _base/momentum=0.9000 | _timers/_fps=31.7417 | _timers/batch_time=2.0163 | _timers/data_time=0.0536 | _timers/model_time=1.9627 | accuracy01=64.0625 | f1_score=0.2947 | loss=0.7014\n",
      "Top best models:\n",
      "models/catalyst/logdir/checkpoints//train.6.pth\t0.6573\n",
      "CPU times: user 3min 9s, sys: 2min 34s, total: 5min 44s\n",
      "Wall time: 9min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# unfreeze bert\n",
    "set_requires_grad(getattr(model, 'distilbert'), True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "callbacks = OrderedDict({\n",
    "    '_criterion': CriterionCallback(),\n",
    "    '_optimizer': OptimizerCallback(accumulation_steps=ACCUM_STEPS),\n",
    "    '_scheduler': SchedulerCallback(),\n",
    "    'accuracy': AccuracyCallback(num_classes=1, threshold=0.5, activation='Sigmoid'),\n",
    "    'f1': F1ScoreCallback()\n",
    "})\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_val_loaders,\n",
    "    callbacks=callbacks,\n",
    "    fp16=FP16_PARAMS,\n",
    "    logdir=LOG_DIR,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    verbose=True,\n",
    "    resume=f\"{LOG_DIR}/checkpoints/best_full.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  8 01:09:45 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   63C    P0    87W / 149W |   1923MiB / 11441MiB |     97%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      2881      C   ...a3/envs/quora_question_pairs/bin/python  1910MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot metrics\n",
    "\n",
    "<img src=\"https://habrastorage.org/webt/ki/ib/hy/kiibhyp373r65zriwruroiqitky.jpeg\" width=30% />\n",
    "\n",
    "There are at least 4 ways to monitor training:\n",
    "\n",
    "### 1. Good old tqdm\n",
    "There above it's set with a flag `verbose` in `runner.train`. Actually, it's not that bad :)\n",
    "\n",
    "<img src='https://habrastorage.org/webt/ta/1s/98/ta1s988ghabz412weaq0lgs_cke.png'> \n",
    "\n",
    "\n",
    "### 2. Weights & Biases\n",
    "\n",
    "Before launching training, you can run [Weighs & Biases](https://app.wandb.ai/) inititialization for this project. Execute `wandb init` in a separate terminal window (from the same directory where this notebook is running). `wandb` will ask your API key from https://app.wandb.ai/authorize and project name. The rest will be picked up by Catalyst's `SupervisedWandbRunner` (so you'll need to import this instead of `SupervisedRunner`). \n",
    "Following the links printed above (smth. like  https://app.wandb.ai/yorko/catalyst-nlp-bert) we can keep track of loss and metrics.\n",
    "\n",
    "### 3. Tensorboard\n",
    "During training, logs are written to `LOG_DIR` specified above. \n",
    "Similtaneously with training, you can run `tensorboard --logdir $LOG_DIR` (in another terminal tab, in case of training on a server, I also had to add a `--bin_all` flag),\n",
    "and you'll get a nice dashboard. Here we see how accuracy and loss change during training.\n",
    "\n",
    "<img src=\"https://habrastorage.org/webt/2a/sx/mo/2asxmoizgcpf2fnhjjkfhvf70aw.png\" width=50% />\n",
    "\n",
    "### 4. Offline metric plotting\n",
    "\n",
    "If your training is pretty fast and/or you're not interested in tracking training progress, you can just plot losses and metrics once the training is done. Looks like it won't work in Kernels though but try it locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Torch loader for the test set and launch `infer` to actually make predictions fot the test set. First, we load the best model checkpoint, then make inference with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = {\n",
    "    \"test\": DataLoader(dataset=test_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint ./models/catalyst/logdir/checkpoints/best.pth\n",
      "loaded checkpoint ./models/catalyst/logdir/checkpoints/best.pth (epoch 6)\n",
      "1/1 * Epoch (test): 100% 2/2 [00:04<00:00,  2.16s/it, _timers/_fps=31.580]\n",
      "Top best models:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.infer(\n",
    "    model=model,\n",
    "    loaders=test_loaders,\n",
    "    callbacks=[\n",
    "        CheckpointCallback(\n",
    "            resume=f\"{LOG_DIR}/checkpoints/best.pth\"\n",
    "        ),\n",
    "        InferCallback(),\n",
    "    ],   \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = runner.callbacks[0].predictions['logits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have predicted probabilities, let's finally create a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df = pd.read_csv(PATH_TO_DATA + 'sample_submission.csv',\n",
    "                           index_col='test_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-68d7a0e806c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpair_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_finetuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigmoid_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_sub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_duplicate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/quora_question_pairs/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "from pair_classification.bert_finetuning.util import sigmoid_np\n",
    "\n",
    "sample_sub_df['is_duplicate'] = sigmoid_np(predicted_probs.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df.to_csv('distillbert_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quora_question_pairs",
   "language": "python",
   "name": "quora_question_pairs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
